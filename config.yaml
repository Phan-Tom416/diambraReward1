folders:
  parent_dir: "./"
  model_name: "agent"

settings:
  game_id: "sfiii3n"
  characters: 'Ryu'
  super_art: 2
  difficulty: 4 
  step_ratio: 3
  frame_shape: !!python/tuple [128,128,1]
  continue_game: 0.9
  action_space: "multi_discrete"
  #attack_but_combination: true 
  #char_outfits: 2
  #player: "Random"
  show_final: true
  #hardcore: true

wrappers_settings:
  #hwc_obs_resize: !!python/tuple [128,128,3]
  normalize_reward: true
  no_attack_buttons_combinations: false
  #frame_stack: 4
  dilation: 1
  #actions_stack: 6
  #reward_normalization: true
  #reward_normalization_factor: 0.7
  #clip_rewards: false
  scale: true
  exclude_image_scaling: true
  flatten: true
  #filter_keys:  ["stage",
                # "P1_ownHealth",
               #  "P1_oppHealth",
              #   "P1_ownSide",
             #    "P1_oppSide",
            #     "P1_oppChar",
           #      "P1_actions_move",
          #       "P1_actions_attack",
         #        "P1_oppStunned",
        #         "P1_oppStunBar",
       #          "P1_ownSuperBar",
      #           "P1_ownSuperCount",
     #            "P1_oppSuperBar",
    #             "P1_oppSuperCount"
   #             ]
  #superbar_wrapper: true  
  #super_hit_wrapper: true
  #opp_super_hit_wrapper: true
  #time_penalty_wrapper: true
  #win_wrapper: true
  #no_hit_wrapper: true
  ##custom_stun_wrapper: true
  #block_wrapper: true
  
policy_kwargs:
  #net_arch: [{vf:[32,32,32],pi:[64,64,64]}]
  #net_arch: [{ pi: [64, 64], vf: [32, 32] }]    
    net_arch: [{vf:[32,32],pi:[64,64]}]
ppo_settings:

  gamma: 0.99
  model_checkpoint: "20480000M"
  learning_rate: [2.5e-4, 2.5e-6] # To start
  #learning_rate: [5.0e-5, 2.5e-6] # Fine Tuning
  clip_range: [0.15, 0.025] # To start
  #clip_range: [0.075, 0.025] # Fine Tuning
  batch_size:
    256 # 8 #nminibatches gave different batch size depending on
    # the number of environments: batch_size = (n_steps * n_envs) // nminibatches
  n_epochs: 4
  n_steps: 256
  autosave_freq: 1280000
  time_steps: 0
