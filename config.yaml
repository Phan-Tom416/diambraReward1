folders:
  parent_dir: "./results/"
  model_name: "sr6_128x4_das_ppo_noHit"

settings:
  game_id: "sfiii3n"
  characters: 'Ryu'
  super_art: 2
  difficulty: 4
  step_ratio: 3
  frame_shape: !!python/tuple [128,128,1]
  continue_game: 0.0
  action_space: "multi_discrete"
  #attack_but_combination: true 
  outfits: 2
  #role: None
  #player: "Random"
  show_final: true
  #hardcore: false


wrappers_settings:
  #hwc_obs_resize: !!python/tuple [128,128,3]
  normalize_reward: true
  no_attack_buttons_combinations: false
  stack_frames: 4
  dilation: 1
  stack_actions: 6
  add_last_action: true
  normalization_factor: 0.7
  clip_reward: false
  scale: true
  exclude_image_scaling: true
  flatten: true
  role_relative: true
  filter_keys:  ['own_character', 
                'own_health',
                'own_side',
                'own_stun_bar',
                'own_stunned',
                'own_super_bar',
                'own_super_count',
                'own_super_max_count',
                'own_super_type',
                'own_wins',
                'opp_character',
                'opp_health',
                'opp_side',
                'opp_stun_bar',
                'opp_stunned',
                'opp_super_bar',
                'opp_super_count',
                'opp_super_max_count',
                'opp_super_type',
                'opp_wins',
                'frame',
                'stage',
                'timer']

  
policy_kwargs:
  #net_arch: [{vf:[32,32,32],pi:[64,64,64]}]
  #net_arch: [{ pi: [64, 64], vf: [32, 32] }]    
  net_arch: {vf:[32,32],pi:[64,64]}
ppo_settings:

  gamma: 0.99
  model_checkpoint: "1280000"
  learning_rate: [2.5e-4, 2.5e-6] # To start
  #learning_rate: [5.0e-5, 2.5e-6] # Fine Tuning
  clip_range: [0.15, 0.025] # To start
  #clip_range: [0.075, 0.025] # Fine Tuning
  batch_size:
    256 # 8 #nminibatches gave different batch size depending on
    # the number of environments: batch_size = (n_steps * n_envs) // nminibatches
  n_epochs: 4
  n_steps: 256
  autosave_freq: 1280000
  time_steps: 0